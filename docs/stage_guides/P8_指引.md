# P8 阶段开发指引 - 端到端联调测试

> **阶段名称**: P8 - 端到端联调测试  
> **预计复杂度**: 高  
> **文档级别**: Level 3 (详细报告)  
> **使用说明**: AI开始P8开发时，只需阅读本文档 + platform_constitution.md

---

## 🎯 阶段目标

完整验证整个"AI游戏开发公司"从启动到交付的全流程：
1. **端到端流程** - 用户输入游戏创意 → AI公司开发 → 产出可玩的游戏
2. **所有模块集成** - P1-P7所有模块协同工作无阻塞
3. **压力测试** - 验证系统稳定性和性能
4. **Bug修复** - 发现并修复联调过程中的所有问题

这是项目的第一个完整里程碑，成功后即可演示给用户。

---

## 📋 核心任务清单

### 必须完成的测试

- [ ] **完整工作流测试**
  - 通过前端启动一个简单游戏项目（如"计数器游戏"）
  - 观察Agent们协作完成7个开发阶段
  - 验证每个阶段的产出（GDD、代码、素材等）
  - 最终获得可运行的游戏文件

- [ ] **Agent通信测试**
  - 验证所有Agent都能正常发送和接收消息
  - 测试广播、点对点、发给老板等消息路由
  - 检查消息频率限制是否生效

- [ ] **人类介入测试**
  - 在关键节点触发决策请求
  - 验证前端正确显示决策面板
  - 提交决策后Agent继续工作

- [ ] **前端实时更新测试**
  - WebSocket实时推送Agent活动
  - 对话面板实时显示消息
  - 状态面板实时更新进度

- [ ] **文件系统测试**
  - 项目目录正确创建
  - 共享知识库文件正确生成
  - 游戏代码文件正确输出

- [ ] **错误恢复测试**
  - WebSocket断开后自动重连
  - Agent工作异常后能恢复或上报
  - 网络抖动不影响整体流程

### 必须修复的Bug

- [ ] 记录并修复联调中发现的所有Bug
- [ ] 优化性能瓶颈（如消息处理延迟）
- [ ] 完善错误处理和日志

---

## 🔗 前置依赖

### P1-P7阶段已完成的所有功能

**后端核心**:
- Agent引擎 (P1)
- 消息总线 + 5个Agent (P2)
- 工具系统 (P3)
- 游戏开发工作流 (P4)
- Web后端API (P5)
- 人类介入机制 (P7)

**前端界面**:
- 可视化界面 (P6)
- 决策面板 (P7)

**全部可用**:
- 所有模块已实现并通过单元测试
- HTTP和WebSocket接口已就绪
- 前后端已分别测试通过

**本阶段任务**:
- 不新增功能，专注于集成测试
- 发现问题 → 修复 → 重测
- 确保整体流程顺畅

---

## ✅ 验证标准

### 端到端流程验证
- [ ] 启动后端服务无报错
- [ ] 打开前端界面正常显示
- [ ] 输入游戏创意（如"一个简单的计数器游戏"）
- [ ] 点击"开始项目"后：
  - [ ] PM接收需求并分配任务
  - [ ] 策划输出GDD文档
  - [ ] 程序员输出代码文件
  - [ ] 测试通过（或触发Bug修复循环）
  - [ ] PM汇报项目完成
- [ ] 在`projects/{project_name}/output/`中找到游戏文件
- [ ] 用浏览器打开游戏能正常运行

### 性能和稳定性验证
- [ ] 整个流程在10-30分钟内完成（取决于游戏复杂度）
- [ ] 无明显卡顿或长时间无响应
- [ ] WebSocket连接稳定，无频繁断连
- [ ] 内存和CPU占用合理

### 用户体验验证
- [ ] 前端实时反馈流畅
- [ ] 错误信息清晰易懂
- [ ] 决策请求时机合理

---

## 🛠️ 推荐使用的Skills

- `python-testing-patterns` - 集成测试和E2E测试
- `llm-evaluation` - LLM输出质量评估
- `logging-best-practices` - 日志分析
- `async-python-patterns` - 异步测试模式

---

## 📐 技术要点

### 关键技术点1: 端到端测试脚本

```python
# test_p8_end_to_end.py
"""
端到端测试：完整运行一次游戏开发流程
"""
import asyncio
import httpx
from pathlib import Path

async def test_full_workflow():
    """测试完整工作流"""
    print("="*60)
    print("🎯 端到端测试：开发一个计数器游戏")
    print("="*60)
    
    # 1. 启动项目
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/project/start",
            json={
                "name": "counter_game",
                "description": "一个简单的计数器游戏，点击按钮数字+1"
            }
        )
        assert response.status_code == 200
        project_id = response.json()["project_id"]
        print(f"✅ 项目已启动: {project_id}")
    
    # 2. 轮询项目状态，等待完成
    max_wait = 1800  # 最多等30分钟
    elapsed = 0
    while elapsed < max_wait:
        await asyncio.sleep(10)
        elapsed += 10
        
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"http://localhost:8000/api/project/{project_id}/status"
            )
            status = response.json()
            
            print(f"⏱️ {elapsed}秒 | 阶段: {status['current_phase']} | 进度: {status['progress']}%")
            
            if status.get('status') == 'completed':
                print("🎉 项目完成！")
                break
            elif status.get('status') == 'failed':
                print(f"❌ 项目失败: {status.get('error')}")
                return False
    
    # 3. 验证输出
    output_dir = Path(f"projects/{project_id}/output")
    assert output_dir.exists(), "输出目录不存在"
    assert (output_dir / "index.html").exists(), "游戏HTML文件不存在"
    
    print("✅ 输出文件验证通过")
    return True
```

### 关键技术点2: 监控和日志分析

在测试过程中，实时监控：
```python
# 监控消息总线
from backend.engine.message_bus import MessageBus

bus = MessageBus()
history = bus.get_history(limit=100)

# 分析消息频率
agent_stats = {}
for msg in history:
    from_agent = msg['from']
    agent_stats[from_agent] = agent_stats.get(from_agent, 0) + 1

print("Agent消息统计:", agent_stats)

# 检查是否有异常的消息循环
# 如果某个Agent发送了超过50条消息，可能陷入了循环
for agent, count in agent_stats.items():
    if count > 50:
        print(f"⚠️ {agent} 消息数异常: {count}条")
```

### 关键技术点3: 分阶段测试策略

```python
# 不要一次运行完整流程，分阶段测试
async def test_phase_by_phase():
    """分阶段测试，便于定位问题"""
    
    # 阶段1: 测试项目启动和立项
    project_id = await test_project_initialization()
    print("✅ 阶段1通过")
    
    # 阶段2: 测试策划阶段
    await test_planning_phase(project_id)
    print("✅ 阶段2通过")
    
    # 阶段3: 测试技术设计
    await test_tech_design_phase(project_id)
    print("✅ 阶段3通过")
    
    # ... 以此类推
```

---

## 🧪 测试方案（自动执行）

### Step 1: 快速回归测试
```bash
python tests/run_regression.py
```
确保所有之前的功能正常

### Step 2: 生成E2E测试脚本
AI按照测试模板生成 `test_p8_end_to_end.py`

### Step 3: 执行端到端测试（用户辅助）

```bash
# Terminal 1: 启动后端
python backend/main.py

# Terminal 2: 运行测试
python test_p8_end_to_end.py

# 或手动测试：
# 1. 打开浏览器 http://localhost:8000/
# 2. 输入游戏创意
# 3. 观察整个流程
```

### Step 4: Bug修复循环
- 发现Bug → AI分析原因 → 修复代码 → 重新测试
- 重复直到无阻塞性Bug

### Step 5: 性能分析
- 记录流程耗时
- 分析瓶颈（LLM调用、文件IO、消息处理）
- 如有严重性能问题，进行优化

---

## 📝 完成后的文档工作（自动执行）

### 1. 更新 platform_constitution.md（必做）
简要记录测试结果和修复的Bug

### 2. 生成详细测试报告（Level 3）
由于P8是关键里程碑，生成400-500行的详细报告：
- 端到端测试结果
- 性能数据（耗时、Token消耗、内存占用）
- 发现和修复的Bug列表
- 优化建议

**可以包含**:
- 详细的测试输出日志
- 性能分析图表（可选）
- 完整的Bug修复过程

---

## 🚀 下一阶段预告

**P9阶段将实现**: 美术集成（接入DALL-E生成游戏素材）

**本阶段需要为P9准备**:
- 确保工作流稳定，P9只需添加美术生成功能
- 提供美术Agent的接口集成点

---

## 💡 开发提示

### 时间分配建议
- 编写测试脚本: 20%
- 执行测试和发现问题: 30%
- 修复Bug: 40%
- 文档和总结: 10%

### 常见问题FAQ

**Q: 如果流程卡住怎么办？**
A: 查看后端日志，找到卡住的Agent，分析是否陷入等待或死循环。

**Q: 如何判断性能是否正常？**
A: 简单游戏（如计数器）应在10-15分钟内完成。如果超过30分钟，需要分析瓶颈。

**Q: 是否需要测试多个游戏项目？**
A: 第一版测试1-2个简单游戏即可，P10再扩展测试更多类型。

**Q: 测试失败后如何定位问题？**
A: 
1. 查看后端日志，找到报错信息
2. 查看消息历史，分析Agent通信
3. 检查文件系统，查看生成的文档
4. 逐个阶段单独测试

---

**指引版本**: v1.0  
**最后更新**: 2026-02-11  
**预计工作量**: 10-15轮对话（包含Bug修复）
