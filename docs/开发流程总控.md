# 开发流程总控文档

> **用途**: AI开发者的总指挥文档，规定P1-P11阶段的标准化流程  
> **目标**: 只需一句话开启开发，AI自动按照优化流程完成所有工作  
> **创建日期**: 2026-02-11  
> **更新日期**: 2026-02-12（🔥 重大调整：P6-P11重新规划，核心目标优先）

---

## 🎯 使用方法（用户视角）

### 标准开场白

用户只需说：

```
请阅读 docs/stage_guides/P{X}_指引.md，并开始开发P{X}阶段
```

**示例**:
- `请阅读 docs/stage_guides/P1_指引.md，并开始开发P1阶段`
- `请阅读 docs/stage_guides/P6_指引.md，并开始开发P6阶段`

AI会自动：
1. 读取 `P{X}_指引.md` + `platform_constitution.md`
2. 理解阶段目标和任务
3. 实现代码
4. 按照新的测试方案测试
5. 按照新的报告模板生成文档（P1-P5已完成，仅查阅）
6. 更新constitution
7. 汇报完成

**无需额外指令**，全自动化！

**注意**: P1-P5阶段已完成，其指引文档标记为"已完成（参考用）"，主要用于查阅和理解已有架构。

---

## 🤖 AI开发流程（AI执行）

### 阶段开始时（自动执行）

当用户说"开始P{X}阶段"时，AI按以下流程工作：

#### Step 1: 读取文档（2个文件）
```
1. docs/stage_guides/P{X}_指引.md  (本阶段任务)
2. docs/platform_constitution.md   (已完成的架构)
```

**不要读取**:
- ❌ `docs/开发计划.md` (太长，1600行)
- ❌ `docs/文档索引.md` (太长，469行)
- ❌ 其他阶段的报告

**Token消耗**: ~3.5万 (vs 原8万，节省55%)

---

#### Step 2: 开发代码

按照指引中的"核心任务清单"实现功能：
- 读取指引中的"前置依赖"，了解可用接口
- 参考"技术要点"，避免常见错误
- 遵循"验证标准"，确保质量

**开发原则**:
- ✅ 使用推荐的Skills
- ✅ 遵守platform_constitution中的架构原则
- ✅ 代码简洁，每个文件<150行
- ✅ 完善的日志和错误处理

---

#### Step 3: 测试验证（按新方案）

按照 `docs/templates/test_template.md` 执行测试：

##### 3.1 快速回归测试（用户运行）
```bash
python tests/run_regression.py
```
AI提示用户运行，验证旧功能未被破坏

##### 3.2 生成本阶段测试（AI生成）
AI按模板生成 `test_p{X}.py`：
- 只测试本阶段新增功能
- 5-8个测试用例
- 每个测试5-15分钟完成
- 清晰的输出格式

**Token消耗**: ~1万 (vs 原5万，节省80%)

##### 3.3 执行测试（用户运行）
```bash
python test_p{X}.py
```
AI提示用户运行，查看结果

##### 3.4 记录结果（AI执行）
- 测试通过 → AI简单记录
- 测试失败 → AI分析并修复

---

#### Step 4: 文档更新（按新方案）

按照指引中的"文档级别"决定：

##### Level 1 (P7, P9): 极简记录
- ✅ 只更新 `platform_constitution.md`
- ❌ 不生成独立阶段报告
- **Token消耗**: ~0（免费更新）

##### Level 2 (P6, P10): 精简报告
- ✅ 更新 `platform_constitution.md`
- ✅ 按 `docs/templates/report_template.md` 生成150-200行报告
- **Token消耗**: ~1.5万（vs 原5万，节省70%)

##### Level 3 (P8): 详细报告
- ✅ 更新 `platform_constitution.md`
- ✅ 生成400-500行详细报告（保留所有章节）
- **Token消耗**: ~5万（关键里程碑，保持详细）

---

#### Step 5: 完成汇报（AI自动）

AI向用户汇报：

```markdown
✅ P{X}阶段开发完成！

## 完成情况
- 实现功能: [列表]
- 测试通过: {X}/{X} (100%)
- 文档更新: ✅

## 下一步
建议开始 P{X+1} 阶段。
使用命令: "请阅读 docs/stage_guides/P{X+1}_指引.md，并开始开发P{X+1}阶段"
```

---

## 📊 优化效果预测

### Token消耗对比（P6-P10五个阶段）

| 阶段 | 原方案Token | 优化方案Token | 节省比例 |
|------|-----------|-------------|---------|
| **文档加载** | 8万×5 = 40万 | 3.5万×5 = 17.5万 | **56%** |
| **测试生成** | 5万×5 = 25万 | 1万×5 = 5万 | **80%** |
| **报告生成** | 5万×5 = 25万 | 8万（分级） | **68%** |
| **总计** | **90万** | **30.5万** | **66%** ✨ |

### 质量影响评估

| 方面 | 影响 | 说明 |
|------|------|------|
| **开发质量** | ✅ 无影响 | 核心流程不变，指引更清晰 |
| **测试覆盖** | ✅ 无影响 | 测试策略更优化（增量测试） |
| **文档完整性** | ⚠️ 轻微影响 | 精简报告少了冗余章节，核心内容都保留 |
| **后续维护** | ✅ 改善 | Constitution记录完整，易于查阅 |
| **用户体验** | ✅ 改善 | 开发更快，沟通更简洁 |

---

## 🎯 各阶段快速参考

### P1: Agent引擎核心（✅ 已完成）
- **复杂度**: 高
- **文档级别**: 参考用
- **实际对话**: 8-12轮

### P2: 消息总线+多Agent协作（✅ 已完成）
- **复杂度**: 高
- **文档级别**: 参考用
- **实际对话**: 约15轮

### P3: 工具系统（✅ 已完成）
- **复杂度**: 中
- **文档级别**: 参考用
- **实际对话**: 约15轮

### P4: 工作流引擎（✅ 已完成）
- **复杂度**: 高
- **文档级别**: 参考用
- **实际对话**: 约12轮

### P5: Web API+前端基础（✅ 已完成）
- **复杂度**: 中
- **文档级别**: 参考用
- **实际对话**: 约10轮

### P6: 实际游戏生成（⏳ 待开发，🔥核心目标）
- **复杂度**: 极高
- **文档级别**: Level 2
- **预计对话**: 15-20轮
- **Token预算**: ~8万
- **⚠️ 重要**: 这是核心目标阶段，必须产出可玩的游戏！

### P7: 人类介入机制（⏳ 待开发）
- **复杂度**: 低
- **文档级别**: Level 1
- **预计对话**: 4-6轮
- **Token预算**: ~3.5万

### P8-1: 2D像素风办公室-必需（⏳ 待开发）
- **复杂度**: 高
- **文档级别**: Level 2
- **预计对话**: 10-12轮
- **Token预算**: ~6万
- **美术风格**: 像素风

### P8-2: 2D像素风办公室-可选（⏳ 待开发，可跳过）
- **复杂度**: 中
- **文档级别**: Level 1
- **预计对话**: 6-8轮
- **Token预算**: ~4万
- **说明**: 如Token预算紧张，可跳过

### P9: 美术集成（⏳ 待开发）
- **复杂度**: 低
- **文档级别**: Level 1
- **预计对话**: 3-5轮
- **Token预算**: ~3.5万

### P10: 端到端联调测试（⏳ 待开发）
- **复杂度**: 高
- **文档级别**: Level 3（详细）
- **预计对话**: 10-15轮
- **Token预算**: ~10万

### P11: 优化完善（⏳ 待开发）
- **复杂度**: 中
- **文档级别**: Level 2
- **预计对话**: 6-10轮
- **Token预算**: ~7万

**P1-P5总计**: ✅ 已完成，约52-64轮对话  
**P6-P11总计**: ⏳ 待开发，54-86轮对话，~42万tokens（如跳过P8-2，约38万tokens）

---

## ⚠️ AI开发者注意事项

### 必须遵守的规则

1. **文档加载规则**
   - ✅ 只读取本阶段指引 + constitution
   - ❌ 不要读取完整开发计划
   - ❌ 不要读取其他阶段的文档

2. **测试规则**
   - ✅ 按模板生成测试脚本
   - ✅ 只测新功能，不重测旧功能
   - ❌ 不要生成详细的测试日志文档

3. **报告规则**
   - ✅ 严格按照指引中的文档级别
   - ✅ Level 1: 不生成独立报告
   - ✅ Level 2: 精简150-200行
   - ✅ Level 3: 详细400-500行

4. **代码规则**
   - ✅ 每个文件<150行
   - ✅ 异步优先（async/await）
   - ✅ 完善的日志记录
   - ✅ 遵守constitution中的架构原则

### 质量检查清单（AI自检）

开发完成后，AI应自我检查：

- [ ] 是否只读取了2个文档（指引+constitution）？
- [ ] 代码是否符合验证标准？
- [ ] 测试是否按模板生成？
- [ ] 文档级别是否正确？
- [ ] 是否更新了constitution？
- [ ] 是否向用户汇报完成情况？

---

## 📋 回归测试管理

### run_regression.py维护规则

每完成一个阶段，将关键测试加入回归测试列表：

```python
# tests/run_regression.py
TESTS = [
    ("P1-LLM客户端", "test_p1.py", "test_llm_client"),
    ("P2-消息总线", "test_p2.py", "test_message_routing"),
    ("P3-文件工具", "test_p3_tools.py", "test_file_tool"),
    ("P4-工作流初始化", "test_p4_workflow.py", "test_workflow_init"),
    ("P5-API健康检查", "test_p5_web_api.py", "test_health_check"),
    # P6完成后添加:
    # ("P6-前端连接", "test_p6.py", "test_websocket_connection"),
    # P7-P10类推...
]
```

**何时添加**:
- 每个阶段完成时，AI自动添加1-2个关键测试
- 不要添加所有测试，只添加最核心的

---

## 🔄 迭代优化

### 模板持续改进

如果在使用过程中发现模板有问题，应及时更新：

**更新优先级**:
1. **高**: 指引模板（影响开发方向）
2. **中**: 测试模板（影响质量验证）
3. **低**: 报告模板（影响文档质量）

**更新流程**:
1. 发现问题 → 记录到issues
2. 讨论改进方案
3. 更新模板文件
4. 更新模板版本号
5. 在后续阶段应用新模板

---

## ✅ 成功标志

P6-P10全部完成后，项目达到"可演示级别"：

- ✅ 用户能输入游戏创意
- ✅ AI公司能自动开发游戏
- ✅ 前端能实时显示开发过程
- ✅ 用户能参与决策
- ✅ 产出可玩的游戏文件
- ✅ 系统稳定可靠
- ✅ Token消耗节省66%
- ✅ 完整文档体系

---

**文档版本**: v1.0  
**最后更新**: 2026-02-11  
**维护者**: AI开发团队  
**下次审查**: P8阶段完成后
